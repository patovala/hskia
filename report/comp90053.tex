%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{url}
\usepackage{amsmath}
\usepackage[shortlabels]{enumitem} 
\usepackage[T1]{fontenc}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkClass} % Top left header
\chead{(\hmwkClassInstructor\ \hmwkClassTime)} % Top center head
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{Python} % Load Python syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf
\lstset{language=Haskell, 
        frame=single, 
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Python functions bold and blue
        keywordstyle=[2]\color{Purple}, % Python function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers                                         
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
        %
        % Put standard Python functions not included in the default language here
        %morekeywords={rand},
        %
        % Put Python function parameters here
        %morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        %morekeywords=[3]{test},
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

% Creates a new command to include a python script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\pythonscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.py}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Programming Project 2013\ \#1} % Assignment title
\newcommand{\hmwkDueDate}{Friday,\ May\ 24,\ 2013} % Due date
\newcommand{\hmwkClass}{COMP90053} % Course/class
\newcommand{\hmwkClassTime}{} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Program Analysis and Transformation} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Diana Barreto, Ivan P. Valarezo} % Your name


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName} id:574386 - id:601099}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\newpage
\newpage

\section{An Interval Analysis for Tip}

\subsection{Introduction}

% this are diana's modifications:
Abstract Interpretation allows to understand and obtain information about all possible
behaviours of a program without executing it. This report presents the design of
an example implementation of abstract interpretation using data flow analysis
(representation of the program using a graph) to know the possible values that could
take the variables in each program point represented by an interval. Therefore the
lattice used to implement the abstract interpretation is the interval lattice.

The implementation was developed using Haskell due to the facilities that this language
allows to implement mathematic expressions the programs that can be analysed are the
ones that could be generated using a language called TIP.

% PV this was my original text
%Symbolic computation allows us to develop algorithms and software for manipulating mathematical expressions, in this sense, this document summarizes the task, steps and parts developed to create interval analysis program developed in Haskell language.

\subsection{Task Solution}
After reviewing the task specifications and information about how to perform the
task[1]. The program was split in the following parts:

% PV this was my original text
%Our solution has been generated according to the  notes about Lattices and Static Analysis \cite{Schwartzbach}. During the development we have done some assumptions in order to overcome possible ambiguities, most of them has been specifically documented in this report.

\begin{itemize}
  \item \emph{Tip Parser (TParse, Syntax)}: This component was built using Happy\footnote{http://www.haskell.org/happy/} and the modules previously provided for this project.
  \item \emph{Tip Flow Generator (TCFlow)}: These modules convert a tip program in a list of CFGNode(s).
  \item \emph{Computation Sequence (TControl)}: This module finds the predecessors of each node of the list of nodes. 
  \item \emph{Interval Operations (TInterval)}: In this module the arithmetic, meet(union) and join(intersect) operations are defined for intervals. 

  \item \emph{Evaluation of Interval Expressions (TEvalInterval)}: This module includes the functionality to transform TIP expressions on interval expressions. Additionally, it includes the functionality to evaluate interval expressions.
  \item \emph{Set of VarState Operations (TVarStateOperations)}: This module contains functions to manipulate a set of variables, and to calculate the new values of the variables.
  \item \emph{Conditionals Constraints (TEvalConditions)}: This module includes the functions to evaluate the constraints that should be added to the variables in the conditionals statements.  
  \item \emph{The Interval Analysis(Main)}: The main module in charge of the interval analysis and widening/narrowing.

\end{itemize}

%The solution has been divided in different modules which performs specific tasks. 
\subsection{Tip Parser}

The parsing provided for this project was developed using Happy Parser Generator. this package has allowed to start with a set of well defined syntax elements to be used in the subsequent phases.


\subsection{Flow Generator and Control Representation}
The first part of this module defines the data type to hold the graph, a linear simple structure based on nodes:

\begin{verbatim}
data CFGNode
    = AsgNode String Exp 
    | OutputNode Exp
    | GotoNode Int
    | IfGotoNode Exp Int 
    | EntryNode
    | ExitNode
    deriving (Show,Eq)

\end{verbatim}

Since interval analysis is performed using forward analysis, this simple structure is useful to produce the set of nodes and predecessors (based on some ideas from \cite{Cousot} and \cite{Bourdoncle}). % PV comented suggested by Diana Also is important to realize that we are working on a lifted lattice of Intervals: $ Intervals = lift({[l,h] \mid l,h \in N \land l \leq h}) $. where $ N = \{-\infty,\cdots,-2,-1,0,1,2,\cdots,\infty\} $, and the order $ [l1,h2] \sqsubseteq [l2,h2]  \Leftrightarrow l1 \leq l2 \land h1 \leq h2 $.


\subsection{Computation sequence} 

After getting the linearized nodes structure, the next step is to traverse the graph to get a collection of predecessors. This is important since this allows to generated a new structure that provides valuable information to  feed the interval analysis.  The Haskell structure that represents this information is composed for a node and a list of Int that contains the id references of each CFGNode from where this node could be reached. The  structure is represented as follows:

\begin{verbatim}
type PredCFGNode = (CFGNode,[Int])
\end{verbatim}

An additional responsibility of this module is to include the operations for collecting the constants (landmarks) to be used in the widening phase.

\subsection{Interval Operations}
The interval operations of this module has been constructed overloading the Haskell type classes for the Ord and Num. Haskell incorporates a strong extendible type scheme, from where have been shaped the data logic and the operations behaviours. The operations created and overloaded are the following:

\begin{description}
  \item[$ \le $] less than or equal
  \item[$ > $] greater than 
  \item[$ + $] interval addition 
  \item[$ - $] interval subtraction
  \item[$ * $] interval multiplication 
  \item[$ \div $] interval division
  \item[$ \cap $] meet (union)
  \item[$ \cup $] join (intersection) 
\end{description}


\subsection{Evaluation of Interval Expressions}

In order to evaluate the program expressions using an interval domain, two main functions were developed and it is important to mention them:

\begin{description}
    \item[transformExp:] 
The tip language have been designed to deal with integers (concrete
domain), however in interval analysis is used the abstract domain of  intervals. For
this reason was created this function that transform Integer expressions in interval
expressions. To perform this task the function follows the patterns given by the structure of integer expressions and as a result that the interval expression data structure is a mirror of the integer one, the conversion is match one pattern again the other.

    \item[evalInterExp:] This function receives an interval expression where the values of the variables have been previously replaced by an interval. It evaluates the expression using interval operations, yielding an Interval as a result. for example it evaluated [0,0]+[1,1] and the result is [1,1].
 In the case of conditional Interval expression (type a > b or a == b) the result of evaluating the expression is [1,1] if the condition is only  \emph{ True } for all interval values. Then the result is [0,0] if the condition is \emph{ False } for all interval numbers and finally if the condition is true for some values and false for others the result of this expression is [0,1].


\end{description}


\subsection{Set of VarState operations}
The set of \emph{ VarState } operations includes auxiliary functions to perform the algorithm
to do the interval analysis. It include for example functions 
to initialize states (bottom or top), functions to union
and intersect \emph{ VarStates } which are used to resolve the equations in each program point and functions to manage to obtain and replace values in a  \emph{ VarState} and in a \emph{ VarState}.

\subsection{Conditionals Constraints}
This module calculates the constraints that should be applied, when a node with a conditional 
expression is obtained in order to have more precise approximations. In the program are considered two types of constraints. First the constraints that are resulted of an expression of type bigger than (>) in this case the constraints are intersect with the value of the variables at this program point to obtain more refined results for the True and False branch. For example if the condition is (j>5) it is possible to say that if the condition is true the values of j should fall in the interval [6,$\infty$] and if it is false the constraint interval should be [$-\infty$,5]. 

The second type of constraints are the ones obtained for the expressions of type (==) in this case for the true branch the constraint is also intersected, however for the false branch the value is optimized if the result of the constraint allows to remove border values, for example, if the condition is j==[0,5] and the value of the variable is [0,10]  it is possible to remove the border to obtain a more refined value of [5,10] for the false branch.


\subsection{The Interval Analysis}
The main data structures involved in the interval analysis are:

\begin{itemize}
\item \emph{ data AbsValue= NoReach | AInterval }: This is a wrap for an Interval to differentiate the value when a variable is bottom(no initialized) or no reachable.
  \item \emph{ type VarState = [(VarName, Interval)] }: This represents the possible values of a
    set of variables in a program point of a tip program.
  \item \emph{ type VarStates = [VarState] }: This represents the possible values that could
    take the set the variables in the different program point as a result of kleene
    iteration.
  \item \emph{ type PredCFGNode = (CFGNode,[Int]) }: A collection of nodes and their predecessors (in a tuple)
\end{itemize}

The Interval Analysis is performed using three main functions:

\begin{description}
  \item[iteration:] This function represents the execution of a kleene iteration, in other words
    this if the function $ f(x_{1},x_{2},...,x_{n}) $ that will be executed n times in order to find the fixed
    point. Consequently this function receives a VarStates with the result of the previous
    execution and returns a new VarStates with the result of the current iteration.

    Additionally, to the \emph{VarStates} of the previous iteration, this function receives a
    \emph{ PredCFGNode } list. The algorithm goal is to process each element of this list and to fulfil this
    task structural induction based in \emph{ CFGNode } is used, it means that a program equation
    was developed for each data constructor of the type \emph{ CFGNode } and the non recursive
    equation or exit case corresponds to the data constructor "Exit Node". 
    Each time that a node is evaluated a new \emph{VarState} is added to the list of \emph{VarStates} that corresponds
    to the state of the current iteration. The program also manages a list of reachable points that allows to each node to know
    if it is a reachable point or not.	
    \\

    For each node in the list the algorithm executes the following steps to decide the \emph{VarState} or value of the variables in each program point for the current iteration:

    \begin{enumerate}
      \item \textbf{Evaluate Reachability}: The first thing that it is evaluated in any kind of node is if it is a reachable point (the element exists in the list of reachable). If it is not reachable, so it is added a \emph{VarState} in the current iteration with all variables with value NR (No Reachable) and nothing is added to the list of not reachable, but if the node is reachable the successors  are added to the list of reachable and the following steps are executed (in a conditional node the successor depends on if the condition is True, False or Both).
      \item \textbf{Union of Predecessors}: This step applies to all kind of nodes and consists in to find the values of the variables in the predecessors nodes and applying union to all of them. If the value of a predecessor node has not been calculated in the current iteration, so the state with the past values is used to obtain them.
      \item \textbf{Intersection with Condition Constraints}: If the node is a conditional (it means the type "IfGotoNode Exp Int") node, so it is possible to restrict the values of the intervals according with the constraints. To do this the result of the union of the predecessors variables is refined intersecting with constraints values. It is important to notice that the information of the constraints is obtained in this point but the information is passed through the program calls to the True and False branch to improve the precision of the intervals in those future program points. 
      
    \end{enumerate}


  \item[wideningState:] This function does the work of widening. This receives two \emph{ VarStates } and
    go over the two \emph{ VarStates } in a recursive way, getting the pair of variables and applying
    the widening operator to generate a new \emph{ VarStates } as a result.

  \item[iterations:] This function controls the process to obtain a fixed point. To do this task it invokes \emph{ iteration } and  \emph{ wideningState } functions. First it calls iteration passing \emph{ VarStates } with the variables initialized in \emph{ Empty }(bottom) as an initial old state. The process invokes this function \emph{ i times }, but before invokes each iteration the algorithm compares if the previous \emph{ VarStates } is equal to the new one and if it is the case means that it is already stabilized and this approximation is returned as the final result. Otherwise when it achieves i iterations it applies widening over the two last  \emph{ VarStates } calculated. This result is the entry to begin a cycle of other \emph{ i times } iterations, which means that narrowing is being applied. To guarantee the end of the program, the process mentions above is executed \emph{ j times } and after that a final approximation is returned.


\end{description}

\section{Dead code elimination Module}

The Optimizer(TOptimizer) module eliminates dead code (Code marked by the Interval Analysis as unreachable). For example:

Given a program like this:

\begin{verbatim}
 i=9;
 if (i>10){
     j=12;
     k=13;
 }else{
     j=0;
     k=0;
 }
 i=12;
\end{verbatim}
 
The algorithm generates this linearization:

\begin{verbatim}
0:<entry>
1:i = "9"
2:if "i > 10" goto 4
3:goto 7
4:j = "12"
5:k = "13"
6:goto 9
7:j = "0"
8:k = "0"
9:i = "12"
10:<exit>
\end{verbatim}

 The widening and interval analysis generates this output:
 
\begin{verbatim}
 0                    | 0:
    <entry>           |    <entry>
 1                    | 1: i=[-oo,oo] j=[-oo,oo] k=[-oo,oo]
    i = 9             |    i = 9
 2                    | 2: i=[9,9] j=[-oo,oo] k=[-oo,oo]
    if i > 10 goto 4  |    if i > 10 goto 4
 3                    | 3: i=[9,9] j=[-oo,oo] k=[-oo,oo]
    goto 7            |    goto 7
 4                    | 4: i=_|_ j=[-oo,oo] k=[-oo,oo]
    j = 12            |    j = 12
 5                    | 5: i=NR j=NR k=NR
    k = 13            |    k = 13
 6                    | 6: i=NR j=NR k=NR
    goto 9            |    goto 9
 7                    | 7: i=NR j=NR k=NR
    j = 0             |    j = 0
 8                    | 8: i=_|_ j=[0,0] k=[-oo,oo]
    k = 0             |    k = 0
 9                    | 9: i=_|_ j=[0,0] k=[0,0]
    i = 12            |    i = 12
 10                   | 10: i=[12,12] j=[0,0] k=[0,0]
    <exit>            |    <exit>

\end{verbatim}

\dots And, the resulting code should be improved like this: 

\begin{verbatim}
 0:<entry>               |0:<entry>               
 1:i = 9                 |1:i = 9                 
 2:if i > 10 goto 4      |2:k = 0                 
 3:goto 7                |3:i = 12                
 4:j = 12                |4:<exit>                
 5:k = 13                |                        
 6:goto 9                |                        
 7:j = 0                 |                        
 8:k = 0                 |                        
 9:i = 12                |                        
 10:<exit>               |                        

\end{verbatim}

The algorithm has these well defined tasks:

\begin{itemize}
  \item Remove the dead code marked as 'NR'  from the interval analyser. 
  \item From the previous step were removed some ``goto'' nodes, so the next step is also to filter the statements that invoked those ``goto'' nodes.
  \item Filter some consecutive ``goto'' nodes. It means, nodes that are pointing to the next lines in the code without any advantage.
  \item Finally, re arrange the nodes, re enumerating the still alive ``if'' and ``goto'' sentences to produce a meaningful output.
\end{itemize}


\section{Fixes to the previous version}
Some improvements done to the previous project:

\begin{itemize}
  \item  Fixed the interval division, It was improved by splitting the intervals in positive and negative values and operating over this subsets. The main purpose is to avoid to deal with divisions by 0.
  \item  Created a new structure for wrapping Interval to mark non reachable branches of code and to differentiate no Initialized from no Reachable.
  \item  In order to improve the handling of some interval operations, the data type ( data SInt = SMinInf | SInt Int | SPlusInf ) and a set of conversion functions were added.
  \item  The Join (union) and Meet (intersect) operations were fixed.
  \item  The conditions for the case false of the conditional (==) were added.
  \item  The neighbours (adding and subtracting one) of the landmarks were added to obtain more precise results.
  \item  The Entry point was modified to initialized the variables in bottom instead of top.
\end{itemize}

Most of the Interval code takes advantage of the \emph{Haskell} deriving feature to make types behave in the intended way. The majority of the \emph{instances} are derived from the following \emph{Class} types:

\begin{description}
  \item[Show:] for presentation
  \item[Eq:] for Bound and Interval evaluation
  \item[Num:] for arithmetic Bound and Interval operations
  \item[Fractional:] for Interval division

\end{description}
  



\section{Lessons Learned}

After finishing this project the main lesson learned is that during the design phase is always important to think about what is the best data structure that could suit in a  given problem, in our case, a not optimal decision was to use an Interval data where the values do not belong to the same data type (was used lower bound Lb and the Upper bound Ub in separated way). This decision complicated the interval operations since all cases had to be analysed independently and in many cases we have difficulties to combine operations with Lb and Ub  and $-\infty$  and $\infty$. It is also important to try to design an extensible and maintainable code to facilitate future improvements.
Finally, This project allows to understand more clearly the concepts of abstract interpretation specially interval analysis. Also it gives us an opportunity to know more about Haskell and, having the opportunity of fix some mistakes after a feedback allowed us to learn even more.

% commented because it is wrooong
% To conclude this interval analysis implementation report for a TIP program, the block graph (\ref{fig:hskia}) illustrates the different steps of data structure feed and transformation in order to obtain the possible approximations of interval values for the TIP variables.
% 
% 
% \begin{figure} % the NFS Architecture 
% \center{\includegraphics[width=0.3\linewidth]{grafico}}
% \caption{Tip Program Transformation}
% \label{fig:hskia}
% \end{figure}


\section{User Guide}
To use the program a compilation \emph{ghc} is required and the procedure is as follow:
\begin{verbatim}
$ ghc --make Main.hs -o hskia
\end{verbatim}

The previous step should generate a \emph{hskia} executable file,
\begin{verbatim}
$ ./hskia 
Usage: hskia [-i -p -a -o] filename

      -a: get the production list from file

      -p: get the predecessors list from file

      -i: start the interval analysis
      
      -o: optimize the code given in filename 
\end{verbatim}

\ldots where:
\begin{description}
  \item[-a] Prints the productions for the tip program in filename, this does not include the interval analysis.
  \item[-p] Prints the predecessors list for debugging the program analysis later, this option also does not include the interval analysis. 
  \item[-i] Starts the interval analysis, including widening and generates the analysis report.
  \item[-o] Creates an optimized version of the tip program <filename>, it includes the interval analysis. 
\end{description}

\bibliographystyle{apacite}
\begin{thebibliography}{XXX}
  \bibitem{Schwartzbach} Schwartzbach, I. , Lecture Notes on Static Analysis. University of Aarthus, Denmark. mis\@bricks.dk.

  \bibitem{Bourdoncle} Bourdoncle, F. (1993, January). Efficient chaotic iteration strategies with widenings. In Formal Methods in Programming and their Applications (pp. 128-141). Springer Berlin Heidelberg.

  \bibitem{Cousot} Cousot, P., \& Cousot, R. (1977, January). Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages (pp. 238-252). ACM.

\end{thebibliography}


\end{document}
